{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****Create a web scraping tool to extract data from websites, such as product prices, stock prices, news articles, etc.****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GET Requests**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.geeksforgeeks.org/python-programming-language/\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Making a GET request\n",
    "r = requests.get('https://www.geeksforgeeks.org/python-programming-language/')\n",
    "\n",
    "# print request object\n",
    "# prints the url requested\n",
    "print(r.url)\n",
    "   \n",
    "# print status code\n",
    "# check status code for response received\n",
    "# success code - 200\n",
    "# <Response [200]>\n",
    "print(r.status_code)\n",
    "\n",
    "# print content of request object\n",
    "# huge! commenting out\n",
    "# print(r.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now to parse above request object content, let's use BeautifulSoup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    " \n",
    " \n",
    "# Making a GET request\n",
    "r = requests.get('https://www.geeksforgeeks.org/python-programming-language/')\n",
    " \n",
    "# check status code for response received\n",
    "# success code - 200\n",
    "print(r)\n",
    " \n",
    "# Parsing the HTML\n",
    "# outputs HTML DOC\n",
    "soup = BeautifulSoup(r.content, 'html.parser')\n",
    "# print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use tags to get the needed data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>Python Programming Language - GeeksforGeeks</title>\n",
      "title\n",
      "html\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    " \n",
    " \n",
    "# Making a GET request\n",
    "r = requests.get('https://www.geeksforgeeks.org/python-programming-language/')\n",
    " \n",
    "# Parsing the HTML\n",
    "soup = BeautifulSoup(r.content, 'html.parser')\n",
    " \n",
    "# Getting the title tag\n",
    "print(soup.title)\n",
    " \n",
    "# Getting the name of the tag\n",
    "print(soup.title.name)\n",
    " \n",
    "# Getting the name of parent tag\n",
    "print(soup.title.parent.name)\n",
    " \n",
    "# use the child attribute to get\n",
    "# the name of the child tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now, let's extract categories of products from urbanic**\n",
    "- Since urbanic is dynamic site, bs4 can't render JavaScript hence \n",
    "    - using selenium\n",
    "    - use webdriver\n",
    "- category div= \"cate_box\"\n",
    "- category name div = \"cate_item\"\n",
    "- ![title](urbanic-categories.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dresses & Skirts \n",
      " Tops \n",
      " Bottoms \n",
      " Sweaters & Sweatshirts \n",
      " Co-ords \n",
      " Outerwears \n",
      " Sports \n",
      " Jewelry \n",
      " Bags \n",
      " Lingerie \n",
      " Pyjamas \n",
      " Swimwear \n",
      " Curve \n",
      " Phone Accessories \n",
      " Other Accessories \n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "# initiating the webdriver.\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "\n",
    "#url of the page we want to scrape\n",
    "url = \"https://in.urbanic.com/category\"\n",
    "\n",
    "driver.get(url) \n",
    "\n",
    "# this is just to ensure that the page is loaded\n",
    "time.sleep(5) \n",
    "  \n",
    "html = driver.page_source\n",
    "  \n",
    "# this renders the JS code and stores all\n",
    "# of the information in static HTML code.\n",
    "  \n",
    "# Now, we could simply apply bs4 to html variable\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "all_divs = soup.find('div', {'class' : 'cate_box'})\n",
    "categories = all_divs.find_all('div', {'class' : 'cate_item'})\n",
    "  \n",
    "# printing all categories\n",
    "for category in categories :\n",
    "    print(category.text)\n",
    "  \n",
    "driver.close() # closing the webdriver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's extract product names and prices**\n",
    "- DOM STRUCTURE\n",
    "- ('ul', {'class' : 'results-base'})\n",
    "    - ('li', {'class' : 'product-base'})\n",
    "        - ('a')\n",
    "            - ('div', {'class' : 'product-productMetaInfo'})\n",
    "                - ('h4', {'class' : 'product-product'}) --->product name here\n",
    "                - ('div', {'class' : 'product-price'})\n",
    "                    - ('span', {'class' : 'product-discountedPrice'}) --->product price here\n",
    "- ![title](namesandprices.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printed A-Line Kurta Rs. 398\n",
      "Women Yoke Design Kurta Set Rs. 887\n",
      "Women Floral Embroidered Georgette Kurta Rs. 659\n",
      "Women Kurta Set With Dupatta Rs. 1529\n",
      "Women Solid Kurta with Palazzos & Dupatta Rs. 539\n",
      "Women Anarkali Kurta Rs. 3442\n",
      "Women Printed Kurta with Trousers With Dupatta Rs. 874\n",
      "Cotton Floral Print Kurta Sets Rs. 1475\n",
      "Kurta with Palazzos & Dupatta Rs. 1899\n",
      "Women Solid Kurta with Trousers & Dupatta Rs. 815\n",
      "Women Kurta With Trouser Rs. 1368\n",
      "Women Kurta With Dupatta Rs. 1199\n",
      "Women Ethnic Motifs Printed Kurta Rs. 644\n",
      "Printed A-Line Kurta Rs. 406\n",
      "Printed Straight Kurta Rs. 809\n",
      "Women Embroidered Kurta Set Rs. 887\n",
      "Women Kurta with Trousers With Dupatta Rs. 1434\n",
      "Women Paisley Checked Anarkali Kurta Rs. 1199\n",
      "Women Embroidered Kurta with Trousers With Dupatta Rs. 1665\n",
      "Printed Anarkali Kurta Rs. 749\n",
      "Pompom Lace Hem Rayon Kurta Rs. 809\n",
      "Cotton Yoke Design Kurta  Set Rs. 1434\n",
      "Women Kurta with Palazzos With Dupatta Rs. 799\n",
      "Women Ethnic Motifs Printed Anarkali Kurta Rs. 1399\n",
      "Embroidered Kurta with Trousers & Dupatta Rs. 999\n",
      "Zari Woven Design Kurta Set Rs. 2699\n",
      "Printed Anarkali Kurta Rs. 749\n",
      "Women Printed Kurta with Trousers With Dupatta Rs. 836\n",
      "Calm Blue and Beige Ethnic Motifs Print Kurta Rs. 689\n",
      "Kurta Set With Dupatta Rs. 2890\n",
      "Women Kurta with Palazzos With Dupatta Rs. 989\n",
      "Women Yoke Design Kurta with Palazzos With Dupatta Rs. 1199\n",
      "Women Embroidered Kurta with Palazzos With Dupatta Rs. 1529\n",
      "Embroidered A-Line Kurta Rs. 412\n",
      "Women Floral Printed Anarkali Kurta Rs. 1299\n",
      "Women Yoke Design Kurta with Trousers With Dupatta Rs. 1399\n",
      "Self Designed Straight Kurta Rs. 341\n",
      "Ethnic Print Kurta Set Rs. 911\n",
      "Women Yoke Design Kurta with Palazzos With Dupatta Rs. 850\n",
      "Women Embroidered Kurta with Trousers With Dupatta Rs. 2319\n",
      "Women Yoke Design Kurta Set Rs. 1199\n",
      "Women Printed Kurta with Trousers With Dupatta Rs. 1169\n",
      "Printed Kurta with Palazzos Rs. 989\n",
      "Women Embroidered Kurta Set Rs. 887\n",
      "Women Yoke Design Kurta Sets Rs. 1539\n",
      "Women Ethnic Motifs Printed Kurta Rs. 1209\n",
      "Women Kurta Set With Dupatta Rs. 850\n",
      "Women Floral Embellished Kurta Rs. 849\n",
      "Women Yoke Design Crepe Kurta Rs. 689\n",
      "Women Kurta with Palazzos With Dupatta Rs. 1229\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "# initiating the webdriver.\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "\n",
    "#url of the page we want to scrape\n",
    "url = \"https://www.myntra.com/women-kurtas-kurtis-suits\"\n",
    "\n",
    "driver.get(url) \n",
    "\n",
    "# this is just to ensure that the page is loaded\n",
    "time.sleep(5) \n",
    "  \n",
    "html = driver.page_source\n",
    "  \n",
    "# this renders the JS code and stores all\n",
    "# of the information in static HTML code.\n",
    "  \n",
    "# Now, we could simply apply bs4 to html variable\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "all_divs = soup.find('ul', {'class' : 'results-base'})\n",
    "products = all_divs.find_all('li', {'class' : 'product-base'})\n",
    "  \n",
    "# printing names and prices of prices\n",
    "for product in products :\n",
    "    atag= product.find('a').find('div', {'class' : 'product-productMetaInfo'})\n",
    "    name= atag.find('h4', {'class' : 'product-product'})    \n",
    "    price = atag.find('div', {'class' : 'product-price'}).find('span', {'class' : 'product-discountedPrice'})\n",
    "    \n",
    "    print(name.text, price.text)\n",
    "\n",
    "# print(products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printed A-Line Kurta Rs. 398\n",
      "Printed A-Line Kurta Rs. 406\n",
      "Embroidered A-Line Kurta Rs. 412\n",
      "Self Designed Straight Kurta Rs. 341\n"
     ]
    }
   ],
   "source": [
    "# printing names and prices of those products whose price <=500\n",
    "for product in products :\n",
    "    atag= product.find('a').find('div', {'class' : 'product-productMetaInfo'})\n",
    "    name= atag.find('h4', {'class' : 'product-product'})    \n",
    "    price = atag.find('div', {'class' : 'product-price'}).find('span', {'class' : 'product-discountedPrice'})\n",
    "    \n",
    "    # list(price.text)=['R','s','.',' ','5','3','5']\n",
    "    if int(\"\".join(list(price.text)[4:]))<=500:\n",
    "        print(name.text, price.text)\n",
    "\n",
    "driver.close() # closing the webdriver"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ee9dfcf03ef883f799e8db599acd57d78b13ea7c83670eb20ef8000875df171a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
